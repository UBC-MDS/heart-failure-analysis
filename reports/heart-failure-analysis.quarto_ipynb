{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2f1850a",
   "metadata": {},
   "source": [
    "---\n",
    "title: Heart Failure Survival Analysis\n",
    "author: \"Merari Santana, Kevin Gao, Gurmehak Kaur, Yuhan Fan\"\n",
    "jupyter: python3\n",
    "format:\n",
    "  html:\n",
    "    toc: true\n",
    "    toc-depth: 2\n",
    "    self-contained: true\n",
    "bibliography: references.bib\n",
    "execute:\n",
    "    echo: false\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b73dbef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "deepchecks - WARNING - You are using deepchecks version 0.18.1, however a newer version is available. Deepchecks is frequently updated with major improvements. You should consider upgrading via the \"python -m pip install --upgrade deepchecks\" command.\n"
     ]
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: false\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import altair as alt\n",
    "import altair_ally as aly\n",
    "import os\n",
    "from vega_datasets import data\n",
    "from sklearn import set_config\n",
    "from sklearn.model_selection import (GridSearchCV, cross_validate, train_test_split,)\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandera as pa\n",
    "from deepchecks.tabular.checks import FeatureLabelCorrelation, FeatureFeatureCorrelation\n",
    "from deepchecks.tabular import Dataset\n",
    "import warnings\n",
    "\n",
    "\n",
    "# Enable Vegafusion for better data transformation\n",
    "#aly.alt.data_transformers.enable('vegafusion')\n",
    "#alt.data_transformers.enable('vegafusion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "tbl-model-metrics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 299 entries, 0 to 298\n",
      "Data columns (total 13 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   age                       299 non-null    float64\n",
      " 1   anaemia                   299 non-null    bool   \n",
      " 2   creatinine_phosphokinase  299 non-null    int64  \n",
      " 3   diabetes                  299 non-null    bool   \n",
      " 4   ejection_fraction         299 non-null    int64  \n",
      " 5   high_blood_pressure       299 non-null    bool   \n",
      " 6   platelets                 299 non-null    float64\n",
      " 7   serum_creatinine          299 non-null    float64\n",
      " 8   serum_sodium              299 non-null    int64  \n",
      " 9   sex                       299 non-null    bool   \n",
      " 10  smoking                   299 non-null    bool   \n",
      " 11  time                      299 non-null    int64  \n",
      " 12  DEATH_EVENT               299 non-null    bool   \n",
      "dtypes: bool(6), float64(3), int64(4)\n",
      "memory usage: 18.2 KB\n",
      "Summary Statistics:\n",
      "Visualizing distributions for all columns...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8200\n",
      "Precision: 0.7000\n",
      "Recall: 0.7400\n",
      "F1 Score: 0.7200\n"
     ]
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: false\n",
    "#| label: tbl-model-metrics\n",
    "#| tbl-cap: Evaluation metrics for the final model.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "file_path = '../data/raw/heart_failure_clinical_records_dataset.csv'\n",
    "heart_failure_data = pd.read_csv(file_path)\n",
    "\n",
    "# List of binary columns\n",
    "binary_columns = ['anaemia', 'diabetes', 'high_blood_pressure', 'sex', 'smoking', 'DEATH_EVENT']\n",
    "\n",
    "# Convert all binary columns to True/False\n",
    "heart_failure_data[binary_columns] = heart_failure_data[binary_columns].astype(bool)\n",
    "\n",
    "heart_failure_data.shape\n",
    "\n",
    "heart_failure_data.info()\n",
    "\n",
    "heart_failure_data['DEATH_EVENT'].value_counts()\n",
    "\n",
    "# Summary statistics\n",
    "print(\"Summary Statistics:\")\n",
    "heart_failure_data.describe()\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = heart_failure_data.isnull().sum()\n",
    "\n",
    "# Convert to a DataFrame for better visualization\n",
    "missing_values_df = pd.DataFrame({\n",
    "    'Column': missing_values.index,\n",
    "    'Missing Values': missing_values.values\n",
    "})\n",
    "\n",
    "# Display the DataFrame\n",
    "missing_values_df\n",
    "\n",
    "aly.heatmap(heart_failure_data,color=\"DEATH_EVENT\")\n",
    "\n",
    "\n",
    "# Distributions of all columns\n",
    "print(\"Visualizing distributions for all columns...\")\n",
    "aly.dist(heart_failure_data)\n",
    "\n",
    "\n",
    "aly.pair(heart_failure_data,color=\"DEATH_EVENT\")\n",
    "\n",
    "aly.corr(data.movies())\n",
    "\n",
    "aly.parcoord(heart_failure_data,color = 'DEATH_EVENT')\n",
    "\n",
    "# Create the distribution plots\n",
    "aly.dist(heart_failure_data,color = 'DEATH_EVENT')\n",
    "\n",
    "#Data Splitting!\n",
    "\n",
    "heart_failure_data = pd.read_csv(file_path)\n",
    "\n",
    "heart_failure_train, heart_failure_test = train_test_split(heart_failure_data, \n",
    "                                                           train_size = 0.8, \n",
    "                                                           stratify = heart_failure_data['DEATH_EVENT'],\n",
    "                                                           random_state = 522)\n",
    "\n",
    "url_processed = '../data/processed/'\n",
    "heart_failure_train.to_csv(os.path.join(url_processed, 'heart_failure_train.csv'))\n",
    "heart_failure_test.to_csv(os.path.join(url_processed, 'heart_failure_test.csv'))\n",
    "\n",
    "#Preprocessing Columns!\n",
    "\n",
    "# Define numeric columns\n",
    "numeric_columns = ['age', 'creatinine_phosphokinase', 'ejection_fraction', \n",
    "                   'platelets', 'serum_creatinine', 'serum_sodium', 'time']\n",
    "# List of binary columns\n",
    "binary_columns = ['anaemia', 'diabetes', 'high_blood_pressure', 'sex', 'smoking']\n",
    "\n",
    "# Convert all binary columns to True/False so they're treated as categorical data\n",
    "heart_failure_train[binary_columns] = heart_failure_train[binary_columns].astype(bool)\n",
    "heart_failure_test[binary_columns] = heart_failure_test[binary_columns].astype(bool)\n",
    "\n",
    "\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (StandardScaler(), numeric_columns),\n",
    "    (OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False, drop='if_binary', dtype = int), binary_columns),\n",
    "    remainder = 'passthrough'\n",
    ")\n",
    "\n",
    "preprocessor.fit(heart_failure_train)\n",
    "heart_failure_scaled_train = preprocessor.transform(heart_failure_train)\n",
    "heart_failure_scaled_test = preprocessor.transform(heart_failure_test)\n",
    "\n",
    "preprocessor.verbose_feature_names_out = False\n",
    "column_names = (preprocessor.get_feature_names_out().tolist())\n",
    "scaled_train = pd.DataFrame(heart_failure_scaled_train, columns=column_names)\n",
    "\n",
    "#Correlation matrix part starts from here:\n",
    "correlation_matrix = scaled_train.drop(columns=['DEATH_EVENT']).corr()\n",
    "correlation_long = correlation_matrix.reset_index().melt(id_vars='index')\n",
    "correlation_long.columns = ['Feature 1', 'Feature 2', 'Correlation']\n",
    "\n",
    "correlation_heatmap = alt.Chart(correlation_long).mark_rect().encode(\n",
    "    x='Feature 1:O',\n",
    "    y='Feature 2:O',\n",
    "    color=alt.Color('Correlation:Q', scale=alt.Scale(scheme='viridis')),\n",
    "    tooltip=['Feature 1', 'Feature 2', 'Correlation']\n",
    ").properties(\n",
    "    width=600,\n",
    "    height=600,\n",
    "    title=\"Correlation Heatmap\"\n",
    ")\n",
    "\n",
    "\n",
    "# Specify the folder path and save the chart\n",
    "folder_path = '../results/figures'  \n",
    "correlation_heatmap.save(f'{folder_path}/correlation_heatmap.png')\n",
    "\n",
    "\n",
    "correlation_heatmap\n",
    "\n",
    "#Based on the correlation matrix graph below, all features have relatively low correlations between each other, \n",
    "#the correlations are below 0.5, so there is no strong evidence to drop additional featues. \n",
    "\n",
    "# validate training data for anomalous correlations between target/response variable \n",
    "# and features/explanatory variables, \n",
    "# as well as anomalous correlations between features/explanatory variables\n",
    "# Do these on training data as part of EDA! \n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"deepchecks\")\n",
    "\n",
    "scaled_train_ds = Dataset(scaled_train, label=\"DEATH_EVENT\", cat_features=[])\n",
    "\n",
    "check_feat_lab_corr = FeatureLabelCorrelation().add_condition_feature_pps_less_than(0.9)\n",
    "check_feat_lab_corr_result = check_feat_lab_corr.run(dataset=scaled_train_ds)\n",
    "\n",
    "check_feat_feat_corr = FeatureFeatureCorrelation().add_condition_max_number_of_pairs_above_threshold(threshold = 0.92, n_pairs = 0)\n",
    "check_feat_feat_corr_result = check_feat_feat_corr.run(dataset=scaled_train_ds)\n",
    "\n",
    "if not check_feat_lab_corr_result.passed_conditions():\n",
    "    raise ValueError(\"Feature-Label correlation exceeds the maximum acceptable threshold.\")\n",
    "\n",
    "if not check_feat_feat_corr_result.passed_conditions():\n",
    "    raise ValueError(\"Feature-feature correlation exceeds the maximum acceptable threshold.\")\n",
    "\n",
    "#Building the model!\n",
    "\n",
    "#Decision Tree\n",
    "pipeline = make_pipeline(\n",
    "        preprocessor, \n",
    "        DecisionTreeClassifier(random_state=522)\n",
    "    )\n",
    "\n",
    "dt_scores = cross_validate(pipeline, \n",
    "                           heart_failure_train.drop(columns=['DEATH_EVENT']), \n",
    "                           heart_failure_train['DEATH_EVENT'],\n",
    "                           return_train_score=True\n",
    "                          )\n",
    "\n",
    "dt_scores = pd.DataFrame(dt_scores).sort_values('test_score', ascending = False)\n",
    "dt_scores\n",
    "\n",
    "\n",
    "#KNN\n",
    "pipeline = make_pipeline(\n",
    "        preprocessor, \n",
    "        KNeighborsClassifier()\n",
    "    )\n",
    "\n",
    "param_grid = {\n",
    "    \"kneighborsclassifier__n_neighbors\": range(1, 100, 3)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=10,  \n",
    "    n_jobs=-1,  \n",
    "    return_train_score=True,\n",
    ")\n",
    "\n",
    "heart_failure_fit = grid_search.fit(heart_failure_train.drop(columns=['DEATH_EVENT']), heart_failure_train['DEATH_EVENT'] )\n",
    "\n",
    "knn_best_model = grid_search.best_estimator_ \n",
    "knn_best_model\n",
    "\n",
    "pd.DataFrame(grid_search.cv_results_).sort_values('mean_test_score', ascending = False)[['params', 'mean_test_score']].iloc[0]\n",
    "\n",
    "#Logistic Regression\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "        preprocessor, \n",
    "        LogisticRegression(random_state=522, max_iter=2000, class_weight = \"balanced\")\n",
    "    )\n",
    "\n",
    "param_grid = {\n",
    "    \"logisticregression__C\": 10.0 ** np.arange(-5, 5, 1)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=10,  \n",
    "    n_jobs=-1,  \n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "heart_failure_fit = grid_search.fit(heart_failure_train.drop(columns=['DEATH_EVENT']), heart_failure_train['DEATH_EVENT'] )\n",
    "\n",
    "lr_best_model = grid_search.best_estimator_.named_steps['logisticregression']\n",
    "lr_best_model\n",
    "\n",
    "lr_scores = pd.DataFrame(grid_search.cv_results_).sort_values('mean_test_score', ascending = False)[['param_logisticregression__C', 'mean_test_score', 'mean_train_score']]\n",
    "lr_scores.iloc[0:5]\n",
    "\n",
    "# Log scale for x-axis, fixed y-axis range, and explicit data type specification\n",
    "lr_train_test_cv = alt.Chart(lr_scores).transform_fold(\n",
    "    [\"mean_test_score\", \"mean_train_score\"],  # Combine columns into one for color differentiation\n",
    "    as_=[\"Score Type\", \"Score\"]  # Rename columns for legend and y-axis\n",
    ").mark_line().encode(\n",
    "    x=alt.X(\"param_logisticregression__C:Q\", \n",
    "            title=\"C (Regularization Parameter)\", \n",
    "            scale=alt.Scale(type='log')),  # Set x-axis to log scale\n",
    "    y=alt.Y(\"Score:Q\", \n",
    "            title=\"Score\", \n",
    "            scale=alt.Scale(domain=[0.75, 0.85])),  # Set y-axis range\n",
    "    color=alt.Color(\"Score Type:N\", \n",
    "                    title=\"Score Type\",  # Add legend title\n",
    "                    scale=alt.Scale(domain=[\"mean_test_score\", \"mean_train_score\"],\n",
    "                                    range=[\"skyblue\", \"pink\"])),  # Map colors to lines\n",
    "    tooltip=[\"param_logisticregression__C\", \"Score Type:N\", \"Score:Q\"]  # Explicitly specify data types in tooltip\n",
    ").properties(\n",
    "    title=\"Training vs Cross-Validation Scores (Log Scale)\",\n",
    "    width=600,\n",
    "    height=400\n",
    ")\n",
    "\n",
    "# Specify the folder path and save the chart\n",
    "folder_path = '../results/figures'  \n",
    "lr_train_test_cv.save(f'{folder_path}/lr_cv_scores.png')\n",
    "\n",
    "lr_train_test_cv\n",
    "\n",
    "features = lr_best_model.coef_\n",
    "feature_names = heart_failure_train.drop(columns=['DEATH_EVENT']).columns\n",
    "coefficients = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': features[0],\n",
    "    'Absolute_Coefficient': abs(features[0])\n",
    "}).sort_values(by='Absolute_Coefficient', ascending=False)\n",
    "\n",
    "coefficients\n",
    "\n",
    "#Model Evaluation!\n",
    "\n",
    "#Confusion Matrix\n",
    "\n",
    "# Confusion Matrix\n",
    "\n",
    "heart_failure_predictions = heart_failure_test.assign(\n",
    "    predicted=heart_failure_fit.predict(heart_failure_test)\n",
    ")\n",
    "\n",
    "cm_crosstab = pd.crosstab(heart_failure_predictions['DEATH_EVENT'], \n",
    "                          heart_failure_predictions['predicted'], \n",
    "                          rownames=[\"Actual\"], \n",
    "                          colnames=[\"Predicted\"]\n",
    "                         )\n",
    "\n",
    "\n",
    "cm_crosstab\n",
    "# cm = confusion_matrix(heart_failure_test[\"DEATH_EVENT\"], heart_failure_fit.predict(heart_failure_test))\n",
    "# cm\n",
    "\n",
    "accuracy = round(accuracy_score(heart_failure_predictions['DEATH_EVENT'], heart_failure_predictions['predicted']),2)\n",
    "precision = round(precision_score(heart_failure_predictions['DEATH_EVENT'], heart_failure_predictions['predicted']),2)\n",
    "recall = round(recall_score(heart_failure_predictions['DEATH_EVENT'], heart_failure_predictions['predicted']),2)\n",
    "f1 = round(f1_score(heart_failure_predictions['DEATH_EVENT'], heart_failure_predictions['predicted']),2)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "tbl-confusion-matrix",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_f4f6f\" style='display:inline'>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Predicted</th>\n",
       "      <th id=\"T_f4f6f_level0_col0\" class=\"col_heading level0 col0\" >0</th>\n",
       "      <th id=\"T_f4f6f_level0_col1\" class=\"col_heading level0 col1\" >1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Actual</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f4f6f_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f4f6f_row0_col0\" class=\"data row0 col0\" >35</td>\n",
       "      <td id=\"T_f4f6f_row0_col1\" class=\"data row0 col1\" >6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f4f6f_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_f4f6f_row1_col0\" class=\"data row1 col0\" >5</td>\n",
       "      <td id=\"T_f4f6f_row1_col1\" class=\"data row1 col1\" >14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x3141e4250>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| label: tbl-confusion-matrix\n",
    "#| tbl-cap: Confusion matrix for the final model on the test dataset.\n",
    "#| echo: false\n",
    "#| output: false\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Generate confusion matrix as a crosstab\n",
    "heart_failure_predictions2 = heart_failure_test.assign(\n",
    "    predicted=heart_failure_fit.predict(heart_failure_test)\n",
    ")\n",
    "\n",
    "cm_crosstab = pd.crosstab(\n",
    "    heart_failure_predictions['DEATH_EVENT'], \n",
    "    heart_failure_predictions['predicted'], \n",
    "    rownames=[\"Actual\"], \n",
    "    colnames=[\"Predicted\"]\n",
    ")\n",
    "TP = cm_crosstab.iloc[1,1]\n",
    "TN = cm_crosstab.iloc[0,0]\n",
    "FP = cm_crosstab.iloc[0,1]\n",
    "FN = cm_crosstab.iloc[1,0]\n",
    "\n",
    "# Render the confusion matrix as it is for correct alignment\n",
    "cm_crosstab.style.set_table_attributes(\"style='display:inline'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12007d3",
   "metadata": {
    "user_expressions": [
     {
      "expression": "accuracy",
      "result": {
       "data": {
        "text/plain": "0.82"
       },
       "metadata": {},
       "status": "ok"
      }
     },
     {
      "expression": "precision",
      "result": {
       "data": {
        "text/plain": "0.7"
       },
       "metadata": {},
       "status": "ok"
      }
     },
     {
      "expression": "recall",
      "result": {
       "data": {
        "text/plain": "0.74"
       },
       "metadata": {},
       "status": "ok"
      }
     },
     {
      "expression": "f1",
      "result": {
       "data": {
        "text/plain": "0.72"
       },
       "metadata": {},
       "status": "ok"
      }
     },
     {
      "expression": "TP",
      "result": {
       "data": {
        "text/plain": "14"
       },
       "metadata": {},
       "status": "ok"
      }
     },
     {
      "expression": "TN",
      "result": {
       "data": {
        "text/plain": "35"
       },
       "metadata": {},
       "status": "ok"
      }
     },
     {
      "expression": "FP",
      "result": {
       "data": {
        "text/plain": "6"
       },
       "metadata": {},
       "status": "ok"
      }
     },
     {
      "expression": "FN",
      "result": {
       "data": {
        "text/plain": "5"
       },
       "metadata": {},
       "status": "ok"
      }
     }
    ]
   },
   "source": [
    "## Summary\n",
    "\n",
    "We built a classification model using the logistic regression algorithm to predict survival outcomes for patients with heart failure. Using patient test results, the final classifier achieves an accuracy of `{python} accuracy`. The model’s precision of `{python} precision` suggests it is moderately conservative in predicting the positive class (death), minimizing false alarms. More importantly, the recall of `{python} recall` ensures the model identifies the majority of high-risk patients, reducing the likelihood of missing true positive cases, which could have serious consequences. The F1-score of `{python} f1` reflects a good balance between precision and recall, highlighting the model’s robustness in survival prediction, see @tbl-model-metrics2.\n",
    "\n",
    "From the confusion matrix, the model correctly identified `{python} TP` patients who passed away (true positives) and`{python} TN` patients who survived (true negatives). However, it also predicted `{python} FP` false positives, incorrectly classifying some survivors as deceased, and missed `{python} FN` actual cases of death (false negatives). While these errors warrant consideration, the model’s performance demonstrates strong predictive capabilities for both positive and negative outcomes, see @tbl-confusion-matrix2.\n",
    "\n",
    "Overall, the logistic regression classifier effectively leverages patient test results to support survival prediction, providing a valuable tool to aid clinical decision-making in heart failure management.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Cardiovascular diseases are responsible for approximately 17 million deaths globally each year, with heart failure and myocardial infarctions being the leading contributors to this staggering toll [@chicco2020]. Electronic medical records from patients with heart failure, collected during follow-up care, provide a wealth of data on symptoms, test results, and clinical outcomes. Leveraging this data, our team applies machine learning algorithms to predict patient survival after heart failure. This approach uncovers critical patterns and insights that might otherwise remain hidden from traditional clinical assessments, offering valuable tools to support medical decision-making and improve patient outcomes. \n",
    "\n",
    "## Data \n",
    "\n",
    "We analyzed a dataset containing the medical records of 299 heart failure patients [@dua2017]. The patients consisted of 105 women and 194 men, and their ages range between 40 and 95 years old. The dataset contains 13 features shown in @tbl-patient-table, which report clinical, body, and lifestyle information [@heartfailuredata]. The **death event** was used as the target variable in our binary classification study. It states whether the patient died or survived before the end of the follow-up period, which lasted 130 days on average. Our dataset has a class imbalance where the number of survived patients (death event = 0) is 203 (67.89%) and the number of dead patients (death event = 1) is 96 (32.11%), see @tbl-death-event-counts.\n",
    "\n",
    "\n",
    "\n",
    "## Explanatory Data Analysis and Visualizations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "tbl-patient-table",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_9616c_row0_col0, #T_9616c_row0_col1, #T_9616c_row1_col0, #T_9616c_row1_col1, #T_9616c_row2_col0, #T_9616c_row2_col1, #T_9616c_row3_col0, #T_9616c_row3_col1, #T_9616c_row4_col0, #T_9616c_row4_col1, #T_9616c_row5_col0, #T_9616c_row5_col1, #T_9616c_row6_col0, #T_9616c_row6_col1, #T_9616c_row7_col0, #T_9616c_row7_col1, #T_9616c_row8_col0, #T_9616c_row8_col1, #T_9616c_row9_col0, #T_9616c_row9_col1, #T_9616c_row10_col0, #T_9616c_row10_col1, #T_9616c_row11_col0, #T_9616c_row11_col1, #T_9616c_row12_col0, #T_9616c_row12_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_9616c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_9616c_level0_col0\" class=\"col_heading level0 col0\" >Column Name</th>\n",
       "      <th id=\"T_9616c_level0_col1\" class=\"col_heading level0 col1\" >Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_9616c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_9616c_row0_col0\" class=\"data row0 col0\" >age</td>\n",
       "      <td id=\"T_9616c_row0_col1\" class=\"data row0 col1\" >Patient's age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9616c_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_9616c_row1_col0\" class=\"data row1 col0\" >anaemia</td>\n",
       "      <td id=\"T_9616c_row1_col1\" class=\"data row1 col1\" >Decrease of red blood cells or hemoglobin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9616c_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_9616c_row2_col0\" class=\"data row2 col0\" >creatinine_phosphokinase</td>\n",
       "      <td id=\"T_9616c_row2_col1\" class=\"data row2 col1\" >Level of the CPK enzyme in the blood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9616c_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_9616c_row3_col0\" class=\"data row3 col0\" >diabetes</td>\n",
       "      <td id=\"T_9616c_row3_col1\" class=\"data row3 col1\" >If the patient has diabetes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9616c_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_9616c_row4_col0\" class=\"data row4 col0\" >ejection_fraction</td>\n",
       "      <td id=\"T_9616c_row4_col1\" class=\"data row4 col1\" >Percentage of blood leaving the heart at each contraction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9616c_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_9616c_row5_col0\" class=\"data row5 col0\" >high_blood_pressure</td>\n",
       "      <td id=\"T_9616c_row5_col1\" class=\"data row5 col1\" >If the patient has hypertension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9616c_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_9616c_row6_col0\" class=\"data row6 col0\" >platelets</td>\n",
       "      <td id=\"T_9616c_row6_col1\" class=\"data row6 col1\" >Platelets in the blood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9616c_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_9616c_row7_col0\" class=\"data row7 col0\" >serum_creatinine</td>\n",
       "      <td id=\"T_9616c_row7_col1\" class=\"data row7 col1\" >Level of serum creatinine in the blood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9616c_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_9616c_row8_col0\" class=\"data row8 col0\" >serum_sodium</td>\n",
       "      <td id=\"T_9616c_row8_col1\" class=\"data row8 col1\" >Level of serum sodium in the blood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9616c_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_9616c_row9_col0\" class=\"data row9 col0\" >sex</td>\n",
       "      <td id=\"T_9616c_row9_col1\" class=\"data row9 col1\" >Woman or man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9616c_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_9616c_row10_col0\" class=\"data row10 col0\" >smoking</td>\n",
       "      <td id=\"T_9616c_row10_col1\" class=\"data row10 col1\" >If the patient smokes or not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9616c_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_9616c_row11_col0\" class=\"data row11 col0\" >time</td>\n",
       "      <td id=\"T_9616c_row11_col1\" class=\"data row11 col1\" >Follow-up period</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9616c_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_9616c_row12_col0\" class=\"data row12 col0\" >DEATH_EVENT</td>\n",
       "      <td id=\"T_9616c_row12_col1\" class=\"data row12 col1\" >Whether the patient died or not (target variable)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x3141e41f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| label: tbl-patient-table\n",
    "#| tbl-cap: Description of the columns in the heart failure dataset.\n",
    "#| echo: false\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the table\n",
    "patient_table = pd.read_csv(\"../results/tables/patient_table.csv\")\n",
    "\n",
    "# Apply CSS to left-align all columns\n",
    "patient_table.style.set_properties(**{'text-align': 'left'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0235f4b3",
   "metadata": {},
   "source": [
    "Based on the correlation matrix graph @fig-correlation_heatmap, all features have relatively low correlations between each other, the correlations are below 0.5, so there is no strong evidence to drop additional features.\n",
    "\n",
    "![Correlation heatmap](../results/figures/correlation_heatmap.png){#fig-correlation_heatmap width=80% fig-pos=\"H\" fig-num=true}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "tbl-missing-values",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_5f920_row0_col0, #T_5f920_row0_col1, #T_5f920_row1_col0, #T_5f920_row1_col1, #T_5f920_row2_col0, #T_5f920_row2_col1, #T_5f920_row3_col0, #T_5f920_row3_col1, #T_5f920_row4_col0, #T_5f920_row4_col1, #T_5f920_row5_col0, #T_5f920_row5_col1, #T_5f920_row6_col0, #T_5f920_row6_col1, #T_5f920_row7_col0, #T_5f920_row7_col1, #T_5f920_row8_col0, #T_5f920_row8_col1, #T_5f920_row9_col0, #T_5f920_row9_col1, #T_5f920_row10_col0, #T_5f920_row10_col1, #T_5f920_row11_col0, #T_5f920_row11_col1, #T_5f920_row12_col0, #T_5f920_row12_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_5f920\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_5f920_level0_col0\" class=\"col_heading level0 col0\" >Column</th>\n",
       "      <th id=\"T_5f920_level0_col1\" class=\"col_heading level0 col1\" >Missing Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5f920_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_5f920_row0_col0\" class=\"data row0 col0\" >age</td>\n",
       "      <td id=\"T_5f920_row0_col1\" class=\"data row0 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5f920_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_5f920_row1_col0\" class=\"data row1 col0\" >anaemia</td>\n",
       "      <td id=\"T_5f920_row1_col1\" class=\"data row1 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5f920_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_5f920_row2_col0\" class=\"data row2 col0\" >creatinine_phosphokinase</td>\n",
       "      <td id=\"T_5f920_row2_col1\" class=\"data row2 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5f920_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_5f920_row3_col0\" class=\"data row3 col0\" >diabetes</td>\n",
       "      <td id=\"T_5f920_row3_col1\" class=\"data row3 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5f920_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_5f920_row4_col0\" class=\"data row4 col0\" >ejection_fraction</td>\n",
       "      <td id=\"T_5f920_row4_col1\" class=\"data row4 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5f920_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_5f920_row5_col0\" class=\"data row5 col0\" >high_blood_pressure</td>\n",
       "      <td id=\"T_5f920_row5_col1\" class=\"data row5 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5f920_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_5f920_row6_col0\" class=\"data row6 col0\" >platelets</td>\n",
       "      <td id=\"T_5f920_row6_col1\" class=\"data row6 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5f920_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_5f920_row7_col0\" class=\"data row7 col0\" >serum_creatinine</td>\n",
       "      <td id=\"T_5f920_row7_col1\" class=\"data row7 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5f920_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_5f920_row8_col0\" class=\"data row8 col0\" >serum_sodium</td>\n",
       "      <td id=\"T_5f920_row8_col1\" class=\"data row8 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5f920_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_5f920_row9_col0\" class=\"data row9 col0\" >sex</td>\n",
       "      <td id=\"T_5f920_row9_col1\" class=\"data row9 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5f920_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_5f920_row10_col0\" class=\"data row10 col0\" >smoking</td>\n",
       "      <td id=\"T_5f920_row10_col1\" class=\"data row10 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5f920_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_5f920_row11_col0\" class=\"data row11 col0\" >time</td>\n",
       "      <td id=\"T_5f920_row11_col1\" class=\"data row11 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5f920_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_5f920_row12_col0\" class=\"data row12 col0\" >DEATH_EVENT</td>\n",
       "      <td id=\"T_5f920_row12_col1\" class=\"data row12 col1\" >0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x3141edf40>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| label: tbl-missing-values\n",
    "#| tbl-cap: Number of missing values in each column of the heart failure dataset.\n",
    "#| echo: false\n",
    "\n",
    "file_path = '../data/raw/heart_failure_clinical_records_dataset.csv'\n",
    "heart_failure_data = pd.read_csv(file_path)\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = heart_failure_data.isnull().sum()\n",
    "\n",
    "# Convert to a DataFrame for better visualization\n",
    "missing_values_df = pd.DataFrame({\n",
    "    'Column': missing_values.index,\n",
    "    'Missing Values': missing_values.values\n",
    "})\n",
    "\n",
    "# Style the DataFrame to align text to the left\n",
    "missing_values_df.style.set_properties(**{'text-align': 'left'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab85202",
   "metadata": {},
   "source": [
    "No missing values, no imputation or filling Nulls required\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "tbl-death-event-counts",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEATH_EVENT</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DEATH_EVENT  Count\n",
       "0            0    203\n",
       "1            1     96"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| label: tbl-death-event-counts\n",
    "#| tbl-cap: Distribution of the target variable `DEATH_EVENT` in the heart failure dataset.\n",
    "#| echo: false\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '../data/raw/heart_failure_clinical_records_dataset.csv'\n",
    "heart_failure_data = pd.read_csv(file_path)\n",
    "\n",
    "# Get value counts for DEATH_EVENT and convert to a DataFrame\n",
    "death_event_counts = heart_failure_data['DEATH_EVENT'].value_counts().reset_index()\n",
    "death_event_counts.columns = ['DEATH_EVENT', 'Count']  # Rename columns\n",
    "\n",
    "# Display the DataFrame as a table\n",
    "death_event_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d783ed9a",
   "metadata": {},
   "source": [
    "Dataset Size: The dataset is relatively small, with only 300 rows. \\\n",
    "Class Imbalance: The target variable, DEATH_EVENT, has few examples in the \"True\" class (i.e., the event occurred), which might affect the model's ability to learn and generalize well. This class imbalance will be taken into consideration during analysis and model evaluation.\n",
    "\n",
    "\n",
    "\n",
    "## Model\n",
    "\n",
    "We compared Decision Tree, KNN, Logistic Regression, and selected Logistic Regression due to its interpretability, and ability to handle both linear and non-linear relationships between features. Logistic Regression performed better than the other two models as it works well with fewer features and is less prone to overfitting compared to more complex models like Decision Trees or KNN, especially when the data is relatively small.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0efd89d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_failure_data = pd.read_csv(file_path)\n",
    "\n",
    "heart_failure_train, heart_failure_test = train_test_split(heart_failure_data, \n",
    "                                                           train_size = 0.8, \n",
    "                                                           stratify = heart_failure_data['DEATH_EVENT'],\n",
    "                                                           random_state = 522)\n",
    "\n",
    "url_processed = '../data/processed/'\n",
    "heart_failure_train.to_csv(os.path.join(url_processed, 'heart_failure_train.csv'))\n",
    "heart_failure_test.to_csv(os.path.join(url_processed, 'heart_failure_test.csv'))\n",
    "\n",
    "# Define numeric columns\n",
    "numeric_columns = ['age', 'creatinine_phosphokinase', 'ejection_fraction', \n",
    "                   'platelets', 'serum_creatinine', 'serum_sodium', 'time']\n",
    "# List of binary columns\n",
    "binary_columns = ['anaemia', 'diabetes', 'high_blood_pressure', 'sex', 'smoking']\n",
    "\n",
    "# Convert all binary columns to True/False so they're treated as categorical data\n",
    "heart_failure_train[binary_columns] = heart_failure_train[binary_columns].astype(bool)\n",
    "heart_failure_test[binary_columns] = heart_failure_test[binary_columns].astype(bool)\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (StandardScaler(), numeric_columns),\n",
    "    (OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False, drop='if_binary', dtype = int), binary_columns),\n",
    "    remainder = 'passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ade3819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.0001, class_weight=&#x27;balanced&#x27;, max_iter=2000,\n",
       "                   random_state=522)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.0001, class_weight=&#x27;balanced&#x27;, max_iter=2000,\n",
       "                   random_state=522)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.0001, class_weight='balanced', max_iter=2000,\n",
       "                   random_state=522)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: false\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "        preprocessor, \n",
    "        LogisticRegression(random_state=522, max_iter=2000, class_weight = \"balanced\")\n",
    "    )\n",
    "\n",
    "param_grid = {\n",
    "    \"logisticregression__C\": 10.0 ** np.arange(-5, 5, 1)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=10,  \n",
    "    n_jobs=-1,  \n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "heart_failure_fit = grid_search.fit(heart_failure_train.drop(columns=['DEATH_EVENT']), heart_failure_train['DEATH_EVENT'] )\n",
    "\n",
    "lr_best_model = grid_search.best_estimator_.named_steps['logisticregression']\n",
    "lr_best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465107e6",
   "metadata": {},
   "source": [
    "Hyperparameter tuning to find find the best Logistic Regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "tbl-lr-scores",
   "metadata": {
    "tbl-num": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_logisticregression__C</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.832428</td>\n",
       "      <td>0.834022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.828261</td>\n",
       "      <td>0.833096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.819928</td>\n",
       "      <td>0.825187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.815761</td>\n",
       "      <td>0.824731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.799275</td>\n",
       "      <td>0.823807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_logisticregression__C  mean_test_score  mean_train_score\n",
       "1                      0.0001         0.832428          0.834022\n",
       "2                       0.001         0.828261          0.833096\n",
       "3                        0.01         0.819928          0.825187\n",
       "4                         0.1         0.815761          0.824731\n",
       "5                         1.0         0.799275          0.823807"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| label: tbl-lr-scores\n",
    "#| tbl-cap: Logistic Regression Scores\n",
    "lr_scores = pd.DataFrame(grid_search.cv_results_).sort_values('mean_test_score', ascending = False)[['param_logisticregression__C', 'mean_test_score', 'mean_train_score']]\n",
    "logregC = lr_scores.iloc[0,0]\n",
    "logreg_cv = round(lr_scores.iloc[0,1],2)\n",
    "lr_scores.iloc[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f643d37",
   "metadata": {
    "user_expressions": [
     {
      "expression": "logregC",
      "result": {
       "data": {
        "text/plain": "0.0001"
       },
       "metadata": {},
       "status": "ok"
      }
     },
     {
      "expression": "logreg_cv",
      "result": {
       "data": {
        "text/plain": "0.83"
       },
       "metadata": {},
       "status": "ok"
      }
     }
    ]
   },
   "source": [
    "**The model is performing well with C = `{python} logregC` with a CV score of `{python} logreg_cv` and is close to train score, indicating that model is generalising well.**\n",
    "\n",
    "![Cross-validation scores for Logistic Regression](../results/figures/lr_cv_scores.png){#fig-lr_cv_scores width=80% fig-pos=\"H\" fig-num=true text-align=\"center\"}\n",
    "\n",
    "Logistic regression performs better than Decision tree and KNN on the cross validation data, hence, we selected it as our final model.\n",
    "\n",
    "\n",
    "The best features to train our model are show in @tbl-top-features:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "tbl-top-features",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Absolute_Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>platelets</td>\n",
       "      <td>-0.006702</td>\n",
       "      <td>0.006702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ejection_fraction</td>\n",
       "      <td>0.004108</td>\n",
       "      <td>0.004108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>creatinine_phosphokinase</td>\n",
       "      <td>-0.003465</td>\n",
       "      <td>0.003465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>0.002880</td>\n",
       "      <td>0.002880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>high_blood_pressure</td>\n",
       "      <td>-0.002383</td>\n",
       "      <td>0.002383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anaemia</td>\n",
       "      <td>0.001004</td>\n",
       "      <td>0.001004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sex</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>serum_creatinine</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.000431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>diabetes</td>\n",
       "      <td>-0.000375</td>\n",
       "      <td>0.000375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>time</td>\n",
       "      <td>-0.000208</td>\n",
       "      <td>0.000208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>smoking</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>0.000106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>serum_sodium</td>\n",
       "      <td>-0.000064</td>\n",
       "      <td>0.000064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Feature  Coefficient  Absolute_Coefficient\n",
       "6                  platelets    -0.006702              0.006702\n",
       "4          ejection_fraction     0.004108              0.004108\n",
       "2   creatinine_phosphokinase    -0.003465              0.003465\n",
       "0                        age     0.002880              0.002880\n",
       "5        high_blood_pressure    -0.002383              0.002383\n",
       "1                    anaemia     0.001004              0.001004\n",
       "9                        sex     0.000714              0.000714\n",
       "7           serum_creatinine     0.000431              0.000431\n",
       "3                   diabetes    -0.000375              0.000375\n",
       "11                      time    -0.000208              0.000208\n",
       "10                   smoking    -0.000106              0.000106\n",
       "8               serum_sodium    -0.000064              0.000064"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| label: tbl-top-features\n",
    "#| tbl-cap: Top features for trainig the model.\n",
    "#| echo: false\n",
    "\n",
    "features = lr_best_model.coef_\n",
    "feature_names = heart_failure_train.drop(columns=['DEATH_EVENT']).columns\n",
    "coefficients = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': features[0],\n",
    "    'Absolute_Coefficient': abs(features[0])\n",
    "}).sort_values(by='Absolute_Coefficient', ascending=False)\n",
    "\n",
    "coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754bf683",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "#### Confusion Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "tbl-confusion-matrix2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_00326\" style='display:inline'>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Predicted</th>\n",
       "      <th id=\"T_00326_level0_col0\" class=\"col_heading level0 col0\" >0</th>\n",
       "      <th id=\"T_00326_level0_col1\" class=\"col_heading level0 col1\" >1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Actual</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_00326_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_00326_row0_col0\" class=\"data row0 col0\" >35</td>\n",
       "      <td id=\"T_00326_row0_col1\" class=\"data row0 col1\" >6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_00326_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_00326_row1_col0\" class=\"data row1 col0\" >5</td>\n",
       "      <td id=\"T_00326_row1_col1\" class=\"data row1 col1\" >14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x3142df490>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| label: tbl-confusion-matrix2\n",
    "#| tbl-cap: Confusion matrix for the final model on the test dataset.\n",
    "#| echo: false\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Generate confusion matrix as a crosstab\n",
    "heart_failure_predictions = heart_failure_test.assign(\n",
    "    predicted=heart_failure_fit.predict(heart_failure_test)\n",
    ")\n",
    "\n",
    "cm_crosstab2 = pd.crosstab(\n",
    "    heart_failure_predictions['DEATH_EVENT'], \n",
    "    heart_failure_predictions['predicted'], \n",
    "    rownames=[\"Actual\"], \n",
    "    colnames=[\"Predicted\"]\n",
    ")\n",
    "TP2 = cm_crosstab.iloc[1,1]\n",
    "TN2 = cm_crosstab.iloc[0,0]\n",
    "FP2 = cm_crosstab.iloc[0,1]\n",
    "FN2 = cm_crosstab.iloc[1,0]\n",
    "\n",
    "# Render the confusion matrix as it is for correct alignment\n",
    "cm_crosstab.style.set_table_attributes(\"style='display:inline'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "tbl-model-metrics2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric  Value\n",
       "0   Accuracy   0.82\n",
       "1  Precision   0.70\n",
       "2     Recall   0.74\n",
       "3   F1 Score   0.72"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| label: tbl-model-metrics2\n",
    "#| tbl-cap: Evaluation metrics for the final model.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy2 = accuracy_score(heart_failure_predictions['DEATH_EVENT'], heart_failure_predictions['predicted'])\n",
    "precision2 = precision_score(heart_failure_predictions['DEATH_EVENT'], heart_failure_predictions['predicted'])\n",
    "recall2 = recall_score(heart_failure_predictions['DEATH_EVENT'], heart_failure_predictions['predicted'])\n",
    "f1_2 = f1_score(heart_failure_predictions['DEATH_EVENT'], heart_failure_predictions['predicted'])\n",
    "\n",
    "# Create a DataFrame for the metrics\n",
    "metrics_table2 = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Value': [accuracy, precision, recall, f1]\n",
    "})\n",
    "\n",
    "# Round values for better readability\n",
    "metrics_table2['Value'] = metrics_table2['Value'].round(4)\n",
    "\n",
    "# Display the DataFrame\n",
    "metrics_table2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a7dbff",
   "metadata": {
    "user_expressions": [
     {
      "expression": "recall",
      "result": {
       "data": {
        "text/plain": "0.74"
       },
       "metadata": {},
       "status": "ok"
      }
     }
    ]
   },
   "source": [
    "## Results and Conculsion\n",
    "\n",
    "The analysis revealed that `platelets` and `ejection_fraction` are the most important features (see @tbl-top-features) in predicting the risk of patient mortality. These features significantly impact the model's ability to assess patient risk, which is crucial for early intervention. Our model achieved a recall score of `{python} recall` (see @tbl-model-metrics2), which is a good start, but there is room for improvement, particularly in reducing the number of high risk patients the model might miss, i.e., maximising recall by minimising False Negatives.\n",
    "\n",
    "The main challenges in this project stem from class imbalance and limited data availability. With more diverse and comprehensive datasets, performance could be further enhanced. We would also like to explore other machine learning models to improve the overall accuracy.\n",
    "\n",
    "In conclusion, while the current model shows potential, there is significant opportunity to enhance its effectiveness. With improvements in data quality and model optimization, this tool could become a crucial asset in predicting patient risk and saving lives.\n",
    "\n",
    "\n",
    "## References\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3",
   "path": "/Users/gurmehak/Documents/MDS/522_ds_workflows/heart-failure-analysis/.venv/share/jupyter/kernels/python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
