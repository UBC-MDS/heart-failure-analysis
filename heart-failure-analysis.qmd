---
title: Heart Failure Survival Analysis
jupyter: python3
format:
  html:
    toc: true
    toc-depth: 2
bibliography: references.bib
execute:
    echo: false
---



by Merari Santana, Kevin Gao, Gurmehak Kaur, Yuhan Fan

## Summary

We built a classification model using the logistic regression algorithm to predict survival outcomes for patients with heart failure. Using patient test results, the final classifier achieves an accuracy of 81.6%. The model’s precision of 70.0% suggests it is moderately conservative in predicting the positive class (death), minimizing false alarms. More importantly, the recall of 73.68% ensures the model identifies the majority of high-risk patients, reducing the likelihood of missing true positive cases, which could have serious consequences. The F1-score of 0.71 reflects a good balance between precision and recall, highlighting the model’s robustness in survival prediction.

From the confusion matrix, the model correctly identified 14 patients who passed away (true positives) and 35 patients who survived (true negatives). However, it also predicted 6 false positives, incorrectly classifying some survivors as deceased, and missed 5 actual cases of death (false negatives). While these errors warrant consideration, the model’s performance demonstrates strong predictive capabilities for both positive and negative outcomes.

Overall, the logistic regression classifier effectively leverages patient test results to support survival prediction, providing a valuable tool to aid clinical decision-making in heart failure management.

## Introduction

Cardiovascular diseases are responsible for approximately 17 million deaths globally each year, with heart failure and myocardial infarctions being the leading contributors to this staggering toll. Electronic medical records from patients with heart failure, collected during follow-up care, provide a wealth of data on symptoms, test results, and clinical outcomes. Leveraging this data, our team applies machine learning algorithms to predict patient survival after heart failure. This approach uncovers critical patterns and insights that might otherwise remain hidden from traditional clinical assessments, offering valuable tools to support medical decision-making and improve patient outcomes. 

## Data 

We analyzed a dataset containing the medical records of 299 heart failure patients. The patients consisted of 105 women and 194 men, and their ages range between 40 and 95 years old. The dataset contains 13 features, which report clinical, body, and lifestyle information. The **death event** was used as the target variable in our binary classification study. It states whether the patient died or survived before the end of the follow-up period, which lasted 130 days on average. Our dataset has a class imbalance where the number of survived patients (death event = 0) is 203 (67.89%) and the number of dead patients (death event = 1) is 96 (32.11%).

| Column Name            | Description                                                  |
|------------------------|--------------------------------------------------------------|
| age                    | Patient's age                                          |
| anaemia                | Decrease of red blood cells or hemoglobin                    |
| creatinine_phosphokinase| Level of the CPK enzyme in the blood                        |
| diabetes               | If the patient has diabetes                                  |
| ejection_fraction      | Percentage of blood leaving the heart at each contraction    |
| high_blood_pressure    | If the patient has hypertension                              |
| platelets              | Platelets in the blood                                       |
| serum_creatinine       | Level of serum creatinine in the blood                       |
| serum_sodium           | Level of serum sodium in the blood                           |
| sex                    | Woman or man                                                 |
| smoking                | If the patient smokes or not                                 |
| time                   | Follow-up period                                             |
| DEATH_EVENT            | Whether the patient died or not (target variable)            |

## Model

We compared Decision Tree, KNN, Logistic Regression, and selected Logistic Regression due to its interpretability, and ability to handle both linear and non-linear relationships between features. Logistic Regression performed better than the other two models as it works well with fewer features and is less prone to overfitting compared to more complex models like Decision Trees or KNN, especially when the data is relatively small.

## Results and Conculsion

The analysis revealed that `platelets` and `ejection_fraction` are the most important features in predicting the risk of patient mortality. These features significantly impact the model's ability to assess patient risk, which is crucial for early intervention. Our model achieved a recall score of 0.73, which is a good start, but there is room for improvement, particularly in reducing the number of high risk patients the model might miss, i.e., maximising recall by minimising False Negatives.

The main challenges in this project stem from class imbalance and limited data availability. With more diverse and comprehensive datasets, performance could be further enhanced. We would also like to explore other machine learning models to improve the overall accuracy.

In conclusion, while the current model shows potential, there is significant opportunity to enhance its effectiveness. With improvements in data quality and model optimization, this tool could become a crucial asset in predicting patient risk and saving lives.

## EDA and Analysis

### Dataset and Imports

```{python}
#| echo: false
#| output: false

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import altair as alt
import altair_ally as aly
import os
from vega_datasets import data
from sklearn import set_config
from sklearn.model_selection import (GridSearchCV, cross_validate, train_test_split,)
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import make_column_transformer
from sklearn.pipeline import make_pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
import pandera as pa
from deepchecks.tabular.checks import FeatureLabelCorrelation, FeatureFeatureCorrelation
from deepchecks.tabular import Dataset
import warnings


# Enable Vegafusion for better data transformation
#aly.alt.data_transformers.enable('vegafusion')
#alt.data_transformers.enable('vegafusion')
```

```{python}
#| echo: false
#| output: false

# Load the dataset
file_path = 'data/heart_failure_clinical_records_dataset.csv'
heart_failure_data = pd.read_csv(file_path)

# List of binary columns
binary_columns = ['anaemia', 'diabetes', 'high_blood_pressure', 'sex', 'smoking', 'DEATH_EVENT']

# Convert all binary columns to True/False
heart_failure_data[binary_columns] = heart_failure_data[binary_columns].astype(bool)
```

### EDA and Visualisations

```{python}
#validate data
schema = pa.DataFrameSchema(
    {
        "age": pa.Column(float, pa.Check.between(1, 120), nullable = True),
        "anaemia": pa.Column(bool),
        "creatinine_phosphokinase": pa.Column(int, pa.Check.between(20, 50000), nullable = True),
        "diabetes": pa.Column(bool),
        "ejection_fraction": pa.Column(int, pa.Check.between(5, 90), nullable = True),
        "high_blood_pressure": pa.Column(bool),
        "platelets": pa.Column(float, pa.Check.between(10000, 900000), nullable = True),
        "serum_creatinine": pa.Column(float, pa.Check.between(0.2, 10), nullable = True),
        "serum_sodium": pa.Column(int, pa.Check.between(110, 190), nullable = True),
        "sex": pa.Column(bool),
        "smoking": pa.Column(bool),
        "time": pa.Column(int, pa.Check.between(1, 360), nullable = True),
        "DEATH_EVENT": pa.Column(bool)
    },
        checks=[
        pa.Check(lambda df: ~df.duplicated().any(), error="Duplicate rows found."),
        pa.Check(lambda df: ~(df.isna().all(axis=1)).any(), error="Empty rows found.")
    ]
)

schema.validate(heart_failure_data, lazy = True)
```

```{python}
heart_failure_data.shape
```

```{python}
heart_failure_data.info()
```

```{python}
heart_failure_data['DEATH_EVENT'].value_counts()
```

* Dataset Size: The dataset is relatively small, with only 300 rows.
* Class Imbalance: The target variable, DEATH_EVENT, has few examples in the "True" class (i.e., the event occurred), which might affect the model's ability to learn and generalize well. This class imbalance will be taken into consideration during analysis and model evaluation.

```{python}
# Summary statistics
print("Summary Statistics:")
heart_failure_data.describe()
```

```{python}
# Check for missing values

missing_values = heart_failure_data.isnull().sum()
print("\nMissing Values:")
print(missing_values)
```

No missing values, no imputation or filling Nulls required

```{python}
aly.heatmap(heart_failure_data,color="DEATH_EVENT")
```

```{python}
# Distributions of all columns
print("Visualizing distributions for all columns...")
aly.dist(heart_failure_data)
```

```{python}
aly.pair(heart_failure_data,color="DEATH_EVENT")
```

```{python}
aly.corr(data.movies())
```

```{python}
aly.parcoord(heart_failure_data,color = 'DEATH_EVENT')
```

```{python}
# Create the distribution plots
aly.dist(heart_failure_data,color = 'DEATH_EVENT')
```

### Data Splitting

```{python}
heart_failure_data = pd.read_csv(file_path)

heart_failure_train, heart_failure_test = train_test_split(heart_failure_data, 
                                                           train_size = 0.8, 
                                                           stratify = heart_failure_data['DEATH_EVENT'],
                                                           random_state = 522)

url_processed = 'data/processed/'
heart_failure_train.to_csv(os.path.join(url_processed, 'heart_failure_train.csv'))
heart_failure_test.to_csv(os.path.join(url_processed, 'heart_failure_test.csv'))
```

### Preprocessing columns

```{python}
# Define numeric columns
numeric_columns = ['age', 'creatinine_phosphokinase', 'ejection_fraction', 
                   'platelets', 'serum_creatinine', 'serum_sodium', 'time']
# List of binary columns
binary_columns = ['anaemia', 'diabetes', 'high_blood_pressure', 'sex', 'smoking']

# Convert all binary columns to True/False so they're treated as categorical data
heart_failure_train[binary_columns] = heart_failure_train[binary_columns].astype(bool)
heart_failure_test[binary_columns] = heart_failure_test[binary_columns].astype(bool)
```

```{python}
preprocessor = make_column_transformer(
    (StandardScaler(), numeric_columns),
    (OneHotEncoder(handle_unknown="ignore", sparse_output=False, drop='if_binary', dtype = int), binary_columns),
    remainder = 'passthrough'
)
```

```{python}
preprocessor.fit(heart_failure_train)
heart_failure_scaled_train = preprocessor.transform(heart_failure_train)
heart_failure_scaled_test = preprocessor.transform(heart_failure_test)

preprocessor.verbose_feature_names_out = False
column_names = (preprocessor.get_feature_names_out().tolist())
scaled_train = pd.DataFrame(heart_failure_scaled_train, columns=column_names)

#Correlation matrix part starts from here:
correlation_matrix = scaled_train.drop(columns=['DEATH_EVENT']).corr()
correlation_long = correlation_matrix.reset_index().melt(id_vars='index')
correlation_long.columns = ['Feature 1', 'Feature 2', 'Correlation']

alt.Chart(correlation_long).mark_rect().encode(
    x='Feature 1:O',
    y='Feature 2:O',
    color=alt.Color('Correlation:Q', scale=alt.Scale(scheme='viridis')),
    tooltip=['Feature 1', 'Feature 2', 'Correlation']
).properties(
    width=600,
    height=600,
    title="Correlation Heatmap"
)

#Based on the correlation matrix graph below, all features have relatively low correlations between each other, 
#the correlations are below 0.5, so there is no strong evidence to drop additional featues. 
```

```{python}
# validate training data for anomalous correlations between target/response variable 
# and features/explanatory variables, 
# as well as anomalous correlations between features/explanatory variables
# Do these on training data as part of EDA! 

warnings.filterwarnings("ignore", category=FutureWarning, module="deepchecks")

scaled_train_ds = Dataset(scaled_train, label="DEATH_EVENT", cat_features=[])

check_feat_lab_corr = FeatureLabelCorrelation().add_condition_feature_pps_less_than(0.9)
check_feat_lab_corr_result = check_feat_lab_corr.run(dataset=scaled_train_ds)

check_feat_feat_corr = FeatureFeatureCorrelation().add_condition_max_number_of_pairs_above_threshold(threshold = 0.92, n_pairs = 0)
check_feat_feat_corr_result = check_feat_feat_corr.run(dataset=scaled_train_ds)

if not check_feat_lab_corr_result.passed_conditions():
    raise ValueError("Feature-Label correlation exceeds the maximum acceptable threshold.")

if not check_feat_feat_corr_result.passed_conditions():
    raise ValueError("Feature-feature correlation exceeds the maximum acceptable threshold.")
```

## Building the Model
Testing Decision Tree, KNN, Logistic Regression

### Decision Tree

```{python}
pipeline = make_pipeline(
        preprocessor, 
        DecisionTreeClassifier(random_state=522)
    )

dt_scores = cross_validate(pipeline, 
                           heart_failure_train.drop(columns=['DEATH_EVENT']), 
                           heart_failure_train['DEATH_EVENT'],
                           return_train_score=True
                          )

dt_scores = pd.DataFrame(dt_scores).sort_values('test_score', ascending = False)
dt_scores
```

### KNN

```{python}
pipeline = make_pipeline(
        preprocessor, 
        KNeighborsClassifier()
    )

param_grid = {
    "kneighborsclassifier__n_neighbors": range(1, 100, 3)
}

grid_search = GridSearchCV(
    pipeline,
    param_grid,
    cv=10,  
    n_jobs=-1,  
    return_train_score=True,
)

heart_failure_fit = grid_search.fit(heart_failure_train.drop(columns=['DEATH_EVENT']), heart_failure_train['DEATH_EVENT'] )

knn_best_model = grid_search.best_estimator_ 
knn_best_model
```

```{python}
pd.DataFrame(grid_search.cv_results_).sort_values('mean_test_score', ascending = False)[['params', 'mean_test_score']].iloc[0]
```

 _

#### Logistic Regression

```{python}
pipeline = make_pipeline(
        preprocessor, 
        LogisticRegression(random_state=522, max_iter=2000, class_weight = "balanced")
    )

param_grid = {
    "logisticregression__C": 10.0 ** np.arange(-5, 5, 1)
}

grid_search = GridSearchCV(
    pipeline,
    param_grid,
    cv=10,  
    n_jobs=-1,  
    return_train_score=True
)

heart_failure_fit = grid_search.fit(heart_failure_train.drop(columns=['DEATH_EVENT']), heart_failure_train['DEATH_EVENT'] )

lr_best_model = grid_search.best_estimator_.named_steps['logisticregression']
lr_best_model
```

```{python}
lr_scores = pd.DataFrame(grid_search.cv_results_).sort_values('mean_test_score', ascending = False)[['param_logisticregression__C', 'mean_test_score', 'mean_train_score']]
lr_scores.iloc[0:5]
```

**Model is performing well with C = 0.0010 with a high test score, close to train score, indicating that model isn't overfitting or underfitting**

```{python}
#| scrolled: true
# Log scale for x-axis, fixed y-axis range, and explicit data type specification
alt.Chart(lr_scores).transform_fold(
    ["mean_test_score", "mean_train_score"],  # Combine columns into one for color differentiation
    as_=["Score Type", "Score"]  # Rename columns for legend and y-axis
).mark_line().encode(
    x=alt.X("param_logisticregression__C:Q", 
            title="C (Regularization Parameter)", 
            scale=alt.Scale(type='log')),  # Set x-axis to log scale
    y=alt.Y("Score:Q", 
            title="Score", 
            scale=alt.Scale(domain=[0.75, 0.85])),  # Set y-axis range
    color=alt.Color("Score Type:N", 
                    title="Score Type",  # Add legend title
                    scale=alt.Scale(domain=["mean_test_score", "mean_train_score"],
                                    range=["skyblue", "pink"])),  # Map colors to lines
    tooltip=["param_logisticregression__C", "Score Type:N", "Score:Q"]  # Explicitly specify data types in tooltip
).properties(
    title="Training vs Cross-Validation Scores (Log Scale)",
    width=600,
    height=400
)
```

**Logistic regression performs better than decision trees and KNN on the cross validation data, hence, we will select it as our final model**

```{python}
features = lr_best_model.coef_
feature_names = heart_failure_train.drop(columns=['DEATH_EVENT']).columns
coefficients = pd.DataFrame({
    'Feature': feature_names,
    'Coefficient': features[0],
    'Absolute_Coefficient': abs(features[0])
}).sort_values(by='Absolute_Coefficient', ascending=False)

coefficients
```

## Model Evaluation

#### Confusion Matrix

```{python}
#| scrolled: true
# Confusion Matrix

heart_failure_predictions = heart_failure_test.assign(
    predicted=heart_failure_fit.predict(heart_failure_test)
)

cm_crosstab = pd.crosstab(heart_failure_predictions['DEATH_EVENT'], 
                          heart_failure_predictions['predicted'], 
                          rownames=["Actual"], 
                          colnames=["Predicted"]
                         )


cm_crosstab
# cm = confusion_matrix(heart_failure_test["DEATH_EVENT"], heart_failure_fit.predict(heart_failure_test))
# cm
```

```{python}
accuracy = accuracy_score(heart_failure_predictions['DEATH_EVENT'], heart_failure_predictions['predicted'])
precision = precision_score(heart_failure_predictions['DEATH_EVENT'], heart_failure_predictions['predicted'])
recall = recall_score(heart_failure_predictions['DEATH_EVENT'], heart_failure_predictions['predicted'])
f1 = f1_score(heart_failure_predictions['DEATH_EVENT'], heart_failure_predictions['predicted'])

print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1:.4f}")
```

## References

Chicco, D., Jurman, G. Machine learning can predict survival of patients with heart failure from serum creatinine and ejection fraction alone. BMC Med Inform Decis Mak 20, 16 (2020). https://doi.org/10.1186/s12911-020-1023-5

Dua, Dheeru, and Casey Graff. 2017. “UCI Machine Learning Repository.” University of California, Irvine, School of Information; Computer Sciences. http://archive.ics.uci.edu/ml.

Heart Failure Clinical Records [Dataset]. (2020). UCI Machine Learning Repository. https://doi.org/10.24432/C5Z89R.

Kuter, David J. "Thrombopoietin and Platelets: Count Regulation." American Journal of Hematology. Wiley Online Library, 2016. Accessed November 27, 2024. https://onlinelibrary.wiley.com/doi/full/10.1002/ajh.23704

Mayo Clinic Staff. "Ejection Fraction: What Does It Measure?" Mayo Clinic, Mayo Foundation for Medical Education and Research. Accessed November 27, 2024. https://www.mayoclinic.org/tests-procedures/ekg/expert-answers/ejection-fraction/faq-20058286

Medical News Today Staff. "What to Know About Serum Creatinine." Medical News Today. Last updated March 22, 2018. Accessed November 27, 2024. https://www.medicalnewstoday.com/articles/322380

MedlinePlus. "Serum Sodium Test." U.S. National Library of Medicine. Last reviewed September 5, 2023. Accessed November 27, 2024. https://medlineplus.gov/ency/article/003481.html

U.S. News Staff. "Creatinine Levels: What You Should Know." U.S. News & World Report. Accessed November 27, 2024. https://health.usnews.com/health-care/patient-advice/articles/creatininelevels


