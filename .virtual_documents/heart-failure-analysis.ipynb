












































import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import altair as alt
import altair_ally as aly
import os
from vega_datasets import data
from sklearn import set_config
from sklearn.model_selection import (GridSearchCV, cross_validate, train_test_split,)
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import make_column_transformer
from sklearn.pipeline import make_pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
import pandera as pa


# Enable Vegafusion for better data transformation
#aly.alt.data_transformers.enable('vegafusion')
#alt.data_transformers.enable('vegafusion')


# Load the dataset
file_path = 'data/heart_failure_clinical_records_dataset.csv'
heart_failure_data = pd.read_csv(file_path)

# List of binary columns
binary_columns = ['anaemia', 'diabetes', 'high_blood_pressure', 'sex', 'smoking', 'DEATH_EVENT']

# Convert all binary columns to True/False
heart_failure_data[binary_columns] = heart_failure_data[binary_columns].astype(bool)





#validate data
schema = pa.DataFrameSchema(
    {
        "age": pa.Column(float, pa.Check.between(1, 120), nullable = True),
        "anaemia": pa.Column(bool),
        "creatinine_phosphokinase": pa.Column(int, pa.Check.between(20, 50000), nullable = True),
        "diabetes": pa.Column(bool),
        "ejection_fraction": pa.Column(int, pa.Check.between(5, 90), nullable = True),
        "high_blood_pressure": pa.Column(bool),
        "platelets": pa.Column(float, pa.Check.between(10000, 900000), nullable = True),
        "serum_creatinine": pa.Column(float, pa.Check.between(0.2, 10), nullable = True),
        "serum_sodium": pa.Column(int, pa.Check.between(110, 190), nullable = True),
        "sex": pa.Column(bool),
        "smoking": pa.Column(bool),
        "time": pa.Column(int, pa.Check.between(1, 360), nullable = True),
        "DEATH_EVENT": pa.Column(bool)
    },
        checks=[
        pa.Check(lambda df: ~df.duplicated().any(), error="Duplicate rows found."),
        pa.Check(lambda df: ~(df.isna().all(axis=1)).any(), error="Empty rows found.")
    ]
)

schema.validate(heart_failure_data, lazy = True)


heart_failure_data.shape


heart_failure_data.info()


heart_failure_data['DEATH_EVENT'].value_counts()





# Summary statistics
print("Summary Statistics:")
heart_failure_data.describe()


# Check for missing values

missing_values = heart_failure_data.isnull().sum()
print("\nMissing Values:")
print(missing_values)





aly.heatmap(heart_failure_data,color="DEATH_EVENT")


# Distributions of all columns
print("Visualizing distributions for all columns...")
aly.dist(heart_failure_data)


aly.pair(heart_failure_data,color="DEATH_EVENT")


aly.corr(data.movies())


aly.parcoord(heart_failure_data,color = 'DEATH_EVENT')


# Create the distribution plots
aly.dist(heart_failure_data,color = 'DEATH_EVENT')





heart_failure_data = pd.read_csv(file_path)

heart_failure_train, heart_failure_test = train_test_split(heart_failure_data, 
                                                           train_size = 0.8, 
                                                           stratify = heart_failure_data['DEATH_EVENT'],
                                                           random_state = 522)

url_processed = 'data/processed/'
heart_failure_train.to_csv(os.path.join(url_processed, 'heart_failure_train.csv'))
heart_failure_test.to_csv(os.path.join(url_processed, 'heart_failure_test.csv'))





# Define numeric columns
numeric_columns = ['age', 'creatinine_phosphokinase', 'ejection_fraction', 
                   'platelets', 'serum_creatinine', 'serum_sodium', 'time']
# List of binary columns
binary_columns = ['anaemia', 'diabetes', 'high_blood_pressure', 'sex', 'smoking']

# Convert all binary columns to True/False so they're treated as categorical data
heart_failure_train[binary_columns] = heart_failure_train[binary_columns].astype(bool)
heart_failure_test[binary_columns] = heart_failure_test[binary_columns].astype(bool)


preprocessor = make_column_transformer(
    (StandardScaler(), numeric_columns),
    (OneHotEncoder(handle_unknown="ignore", sparse_output=False, drop='if_binary', dtype = int), binary_columns),
    remainder = 'passthrough'
)

# preprocessor.fit(heart_failure_train)
# heart_failure_scaled_train = preprocessor.transform(heart_failure_train)
# heart_failure_scaled_test = preprocessor.transform(heart_failure_test)








pipeline = make_pipeline(
        preprocessor, 
        DecisionTreeClassifier(random_state=522)
    )

dt_scores = cross_validate(pipeline, 
                           heart_failure_train.drop(columns=['DEATH_EVENT']), 
                           heart_failure_train['DEATH_EVENT'],
                           return_train_score=True
                          )

dt_scores = pd.DataFrame(dt_scores).sort_values('test_score', ascending = False)
dt_scores





pipeline = make_pipeline(
        preprocessor, 
        KNeighborsClassifier()
    )

param_grid = {
    "kneighborsclassifier__n_neighbors": range(1, 100, 3)
}

grid_search = GridSearchCV(
    pipeline,
    param_grid,
    cv=10,  
    n_jobs=-1,  
    return_train_score=True,
)

heart_failure_fit = grid_search.fit(heart_failure_train.drop(columns=['DEATH_EVENT']), heart_failure_train['DEATH_EVENT'] )

knn_best_model = grid_search.best_estimator_ 
knn_best_model


pd.DataFrame(grid_search.cv_results_).sort_values('mean_test_score', ascending = False)[['params', 'mean_test_score']].iloc[0]








pipeline = make_pipeline(
        preprocessor, 
        LogisticRegression(random_state=522, max_iter=2000, class_weight = "balanced")
    )

param_grid = {
    "logisticregression__C": 10.0 ** np.arange(-5, 5, 1)
}

grid_search = GridSearchCV(
    pipeline,
    param_grid,
    cv=10,  
    n_jobs=-1,  
    return_train_score=True
)

heart_failure_fit = grid_search.fit(heart_failure_train.drop(columns=['DEATH_EVENT']), heart_failure_train['DEATH_EVENT'] )

lr_best_model = grid_search.best_estimator_.named_steps['logisticregression']
lr_best_model


lr_scores = pd.DataFrame(grid_search.cv_results_).sort_values('mean_test_score', ascending = False)[['param_logisticregression__C', 'mean_test_score', 'mean_train_score']]
lr_scores.iloc[0:5]





# Log scale for x-axis, fixed y-axis range, and explicit data type specification
alt.Chart(lr_scores).transform_fold(
    ["mean_test_score", "mean_train_score"],  # Combine columns into one for color differentiation
    as_=["Score Type", "Score"]  # Rename columns for legend and y-axis
).mark_line().encode(
    x=alt.X("param_logisticregression__C:Q", 
            title="C (Regularization Parameter)", 
            scale=alt.Scale(type='log')),  # Set x-axis to log scale
    y=alt.Y("Score:Q", 
            title="Score", 
            scale=alt.Scale(domain=[0.75, 0.85])),  # Set y-axis range
    color=alt.Color("Score Type:N", 
                    title="Score Type",  # Add legend title
                    scale=alt.Scale(domain=["mean_test_score", "mean_train_score"],
                                    range=["skyblue", "pink"])),  # Map colors to lines
    tooltip=["param_logisticregression__C", "Score Type:N", "Score:Q"]  # Explicitly specify data types in tooltip
).properties(
    title="Training vs Cross-Validation Scores (Log Scale)",
    width=600,
    height=400
)





features = lr_best_model.coef_
feature_names = heart_failure_train.drop(columns=['DEATH_EVENT']).columns
coefficients = pd.DataFrame({
    'Feature': feature_names,
    'Coefficient': features[0],
    'Absolute_Coefficient': abs(features[0])
}).sort_values(by='Absolute_Coefficient', ascending=False)

coefficients








# Confusion Matrix

heart_failure_predictions = heart_failure_test.assign(
    predicted=heart_failure_fit.predict(heart_failure_test)
)

cm_crosstab = pd.crosstab(heart_failure_predictions['DEATH_EVENT'], 
                          heart_failure_predictions['predicted'], 
                          rownames=["Actual"], 
                          colnames=["Predicted"]
                         )


cm_crosstab
# cm = confusion_matrix(heart_failure_test["DEATH_EVENT"], heart_failure_fit.predict(heart_failure_test))
# cm


accuracy = accuracy_score(heart_failure_predictions['DEATH_EVENT'], heart_failure_predictions['predicted'])
precision = precision_score(heart_failure_predictions['DEATH_EVENT'], heart_failure_predictions['predicted'])
recall = recall_score(heart_failure_predictions['DEATH_EVENT'], heart_failure_predictions['predicted'])
f1 = f1_score(heart_failure_predictions['DEATH_EVENT'], heart_failure_predictions['predicted'])

print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1:.4f}")






